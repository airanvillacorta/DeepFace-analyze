{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T12:47:28.317843Z",
     "iopub.status.busy": "2022-05-15T12:47:28.317524Z",
     "iopub.status.idle": "2022-05-15T12:47:37.510600Z",
     "shell.execute_reply": "2022-05-15T12:47:37.509800Z",
     "shell.execute_reply.started": "2022-05-15T12:47:28.317810Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-15T12:47:37.512439Z",
     "iopub.status.busy": "2022-05-15T12:47:37.512187Z",
     "iopub.status.idle": "2022-05-15T12:47:37.517598Z",
     "shell.execute_reply": "2022-05-15T12:47:37.516762Z",
     "shell.execute_reply.started": "2022-05-15T12:47:37.512409Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T12:47:37.519012Z",
     "iopub.status.busy": "2022-05-15T12:47:37.518786Z",
     "iopub.status.idle": "2022-05-15T12:47:37.530087Z",
     "shell.execute_reply": "2022-05-15T12:47:37.529383Z",
     "shell.execute_reply.started": "2022-05-15T12:47:37.518985Z"
    }
   },
   "outputs": [],
   "source": [
    "#-Airan: Parametrización\n",
    "\n",
    "SIZE_DEFAULT = (143, 181) # Tamaño por defecto de las imagenes.\n",
    "SIZE_TRANSFORM = [(143, 181), (71, 90), (35, 45), (17, 22)] #143*181 - 71*90 - 35*45 - 17*22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T12:47:37.531637Z",
     "iopub.status.busy": "2022-05-15T12:47:37.531406Z",
     "iopub.status.idle": "2022-05-15T12:47:37.550315Z",
     "shell.execute_reply": "2022-05-15T12:47:37.549493Z",
     "shell.execute_reply.started": "2022-05-15T12:47:37.531608Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(size, path): # Default\n",
    "    print('INICIANDO PROCESADO. Tamaño de procesamiento:',size)\n",
    "    #-Airan: Información y muestra 1º elemento\n",
    "    first = True\n",
    "    elemento = 'NaN'\n",
    "    #-Airán: Contador de elementos procesados\n",
    "    elementos_procesados = 0\n",
    "    \n",
    "    sub_paths = ['Train', 'Validation'] #-Airan: Sub_Path\n",
    "\n",
    "    y = []\n",
    "    y_pred = []\n",
    "    \n",
    "    y_train = []\n",
    "    y_pred_train = []\n",
    "    \n",
    "    y_validation = []\n",
    "    y_pred_validation = []\n",
    "\n",
    "    # Carpetas con muestras\n",
    "    folders = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise' ]\n",
    "    # Etiquetas del clasificador\n",
    "    classlabels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise' ]\n",
    "\n",
    "    # Cada carpeta un índice de clase numérico\n",
    "    n_clases = 0\n",
    "    for fex in folders:\n",
    "\n",
    "        for sub_path in sub_paths: #-Airan: Obtener todo el dataset: Train, Validation\n",
    "\n",
    "            folder = os.path.join((path + sub_path), fex)\n",
    "\n",
    "            for file_name in os.listdir(folder):\n",
    "\n",
    "                # Asume imágenes en formato png\n",
    "                if file_name.endswith('.png'):\n",
    "                    \n",
    "                    abs_path = os.path.join(folder, file_name) #-Airan: Ruta completa imagen\n",
    "                    \n",
    "                    elementos_procesados += 1\n",
    "                    \n",
    "                    #-Airán: Información y muestra 1º elemento\n",
    "                    if first:\n",
    "                        elemento = abs_path\n",
    "                        first = False                        \n",
    "                    \n",
    "                    #-Airan: Lee la imagen\n",
    "                    image = cv2.imread(abs_path)\n",
    "                    \n",
    "                    #-Airan: Modificación tamaño imagen\n",
    "                    if size != SIZE_DEFAULT: # Simulación diferente a la default\n",
    "                        image = cv2.resize(image, size) # Airán\n",
    "\n",
    "                    # Procesa la imagen que asume hay cara, no fuerza la detección\n",
    "                    # Añadimos directamente la imagen. DeepFace, admite tanto imagen como path.\n",
    "                    obj = DeepFace.analyze(image, enforce_detection=False, actions = ['emotion']) #-Airan: Image\n",
    "\n",
    "                    #--- Conjunto completo.\n",
    "                    y.append(n_clases) # Anotación, índice de la carpeta procesando\n",
    "                    y_pred.append(classlabels.index(obj[\"dominant_emotion\"])) # Predicción en formato numérico\n",
    "                    #--- Conjunto Train.\n",
    "                    if sub_path == sub_paths[0]:\n",
    "                        y_train.append(n_clases)\n",
    "                        y_pred_train.append(classlabels.index(obj[\"dominant_emotion\"]))\n",
    "                    #--- Conjunto Validation.\n",
    "                    if sub_path == sub_paths[1]:\n",
    "                        y_validation.append(n_clases)\n",
    "                        y_pred_validation.append(classlabels.index(obj[\"dominant_emotion\"]))\n",
    "                        \n",
    "                    \n",
    "        n_clases += 1\n",
    "        \n",
    "    print('\\nINFORMACIÓN DATASET')\n",
    "    print('Número de carpetas:', len(folders))\n",
    "    print('Número de clases:', len(classlabels))\n",
    "    img = cv2.imread(elemento)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if size != SIZE_DEFAULT: # Simulación diferente a la default\n",
    "        img = cv2.resize(img, size)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print('Tamaño de la imagen:',size)\n",
    "    print('Elementos procesados:',elementos_procesados)\n",
    "    \n",
    "    #--- Información de los resultados obtenidos:\n",
    "\n",
    "    print(\"\\nDeepFace FER Metrics\") # Reconocimiento Facial de Emociones.\n",
    "    \n",
    "    #--- Información Conjunto Completo:\n",
    "    print(\"\\nInformación Conjunto Completo\")\n",
    "    precision_score(y, y_pred, average='weighted')\n",
    "    recall_score(y, y_pred, average='weighted')\n",
    "    print(classification_report(y, y_pred, target_names=classlabels))\n",
    "    print(\"Confussion matrix:\")\n",
    "    print(confusion_matrix(y, y_pred, labels=range(n_clases)))\n",
    "    #--- Información Conjunto Train:\n",
    "    print(\"\\nInformación Conjunto Train\")\n",
    "    precision_score(y_train, y_pred_train, average='weighted')\n",
    "    recall_score(y_train, y_pred_train, average='weighted')\n",
    "    print(classification_report(y_train, y_pred_train, target_names=classlabels))\n",
    "    print(\"Confussion matrix:\")\n",
    "    print(confusion_matrix(y_train, y_pred_train, labels=range(n_clases)))\n",
    "    #--- Información Conjunto Validation:\n",
    "    print(\"\\nInformación Conjunto Validation\")\n",
    "    precision_score(y_validation, y_pred_validation, average='weighted')\n",
    "    recall_score(y_validation, y_pred_validation, average='weighted')\n",
    "    print(classification_report(y_validation, y_pred_validation, target_names=classlabels))\n",
    "    print(\"Confussion matrix:\")\n",
    "    print(confusion_matrix(y_validation, y_pred_validation, labels=range(n_clases)))\n",
    "    print('FIN PROCESADO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T12:47:37.552197Z",
     "iopub.status.busy": "2022-05-15T12:47:37.551967Z",
     "iopub.status.idle": "2022-05-15T12:53:03.960659Z",
     "shell.execute_reply": "2022-05-15T12:53:03.959481Z",
     "shell.execute_reply.started": "2022-05-15T12:47:37.552170Z"
    }
   },
   "outputs": [],
   "source": [
    "#-SIMULATIONS:\n",
    "print('--- INICIO SIMULACIÓN ---')\n",
    "count = 1\n",
    "for size in SIZE_TRANSFORM:\n",
    "    print('\\nSimulación:',count)\n",
    "    process_data(size, '../input/DataSetsSFEW/SFEW/')\n",
    "    count += 1\n",
    "print('--- FIN SIMULACIÓN ---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
